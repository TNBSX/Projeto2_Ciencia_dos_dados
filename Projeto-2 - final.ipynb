{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "#### Por: Marcelo Lisboa de Castro Reis e Tiago Niemeyer Bergamo - 2C Engenharia Insper\n",
    "\n",
    "Vocês foram contratados por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que vocês criem um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como alunos de Ciência dos Dados, vocês lembraram do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, vocês precisam implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 21/Set até às 23:59.<br />\n",
    "Grupo: 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**O nosso projeto pode ser encontrado no seguinte GitHub:** https://github.com/Marcelolcr/Projeto-1---Ciencia-de-Dados.git\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o dataframe Treinamento\n",
    "netflix = pd.read_excel('netflix_´p2.xlsx')\n",
    "#netflix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando os dados\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace(',','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace(':','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('|','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('.','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('\"','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('”','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('“','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace(';','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('!',' !')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('?',' ?')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('(','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('+','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace(')','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('\\n','')\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.replace('/','') #\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.strip()\n",
    "netflix['Treinamento'] = netflix['Treinamento'].str.lower()\n",
    "#netflix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os dados já classificados em dois grupos: relevantes e irrelevantes\n",
    "pal_relevantes = netflix[netflix['R ou I']=='Relevante']\n",
    "pal_irrelevantes = netflix[netflix['R ou I']=='Irrelevante']\n",
    "\n",
    "netflix_lista_palavras_rel = pal_relevantes['Treinamento'].str.split()\n",
    "netflix_lista_palavras_irrel = pal_irrelevantes['Treinamento'].str.split()\n",
    "\n",
    "#Criando novos DataFrames para cada grupo e limpando mais \n",
    "Novo_DF_R = pd.DataFrame(np.array(netflix_lista_palavras_rel), columns=['Relevantes'])\n",
    "Novo_DF_I = pd.DataFrame(np.array(netflix_lista_palavras_irrel), columns=['Irrelevantes'])\n",
    "\n",
    "for linha in Novo_DF_R['Relevantes']:\n",
    "    for p in linha:\n",
    "        if '@' in p:\n",
    "            linha.remove(p)\n",
    "        if 'https'in p:\n",
    "            linha.remove(p)\n",
    "        if ' ' in p:\n",
    "            linha.remove(p)\n",
    "            \n",
    "for l in Novo_DF_I['Irrelevantes']:\n",
    "    for pal in l:\n",
    "        if '@' in pal:\n",
    "            l.remove(pal)\n",
    "        if 'https' in pal:\n",
    "            l.remove(pal)\n",
    "        if ' ' in pal:\n",
    "            l.remove(pal)\n",
    "            \n",
    "#Probabilidades totais\n",
    "prob_rel = len(pal_relevantes)/len(netflix)\n",
    "prob_irrel = len(pal_irrelevantes)/len(netflix)\n",
    "#Novo_DF_I.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166\n",
      "1728\n",
      "3281\n"
     ]
    }
   ],
   "source": [
    "#Colocando todas as palavras em uma mesma lista\n",
    "palavras_R = []\n",
    "for pal in netflix_lista_palavras_rel:\n",
    "    for p in pal:\n",
    "        palavras_R.append(p)\n",
    "\n",
    "palavras_I = []\n",
    "for pal in netflix_lista_palavras_irrel:\n",
    "    for p in pal:\n",
    "        palavras_I.append(p)\n",
    "\n",
    "#Tirando os usernames e links da lista\n",
    "for pal in palavras_R:\n",
    "    if '@' in pal:\n",
    "        palavras_R.remove(pal)\n",
    "    if \"https\" in pal:\n",
    "        palavras_R.remove(pal)\n",
    "        \n",
    "for pal in palavras_I:\n",
    "    if '@' in pal:\n",
    "        palavras_I.remove(pal)\n",
    "    if \"https\" in pal:\n",
    "        palavras_I.remove(pal)\n",
    "\n",
    "#Calculando o total de palavras diferentes na nossa base Treinamento\n",
    "PALAVRAS_RI = []\n",
    "for e in palavras_R:\n",
    "    if e not in PALAVRAS_RI:\n",
    "        PALAVRAS_RI.append(e)\n",
    "for e in palavras_I:\n",
    "    if e not in PALAVRAS_RI:\n",
    "        PALAVRAS_RI.append(e)\n",
    "\n",
    "print(len(PALAVRAS_RI))\n",
    "\n",
    "#Claculando o numero de palavras relevantes e irrelevantes em cada uma das listas\n",
    "print(len(palavras_R))\n",
    "print(len(palavras_I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando lista de tweets agora\n",
    "Lista_tweets_R = []\n",
    "for listas in Novo_DF_R[\"Relevantes\"]:\n",
    "    Lista_tweets_R.append(listas)\n",
    "#print(Lista_tweets_R)\n",
    "\n",
    "Lista_tweets_I = []\n",
    "for listas in Novo_DF_I[\"Irrelevantes\"]:\n",
    "    Lista_tweets_I.append(listas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequencia de palavras relevantes \n",
    "D_Relevante = {}\n",
    "for e in palavras_R:\n",
    "    if e not in D_Relevante:\n",
    "        D_Relevante[e] = 1\n",
    "    elif e in D_Relevante:\n",
    "        D_Relevante[e] += 1\n",
    "\n",
    "#Probabilidade de palavras relevantes (não será necessário com o laplace)\n",
    "PROB_1000_R = {}\n",
    "for e in D_Relevante:\n",
    "    probabilidades = D_Relevante[e]/len(palavras_R)\n",
    "    PROB_1000_R[e] = probabilidades\n",
    "#print(PROB_1000_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequencia de palavras irrelevantes\n",
    "D_Irrelevante = {}\n",
    "for e in palavras_I:\n",
    "    if e not in D_Irrelevante:\n",
    "        D_Irrelevante[e] = 1\n",
    "    elif e in D_Irrelevante:\n",
    "        D_Irrelevante[e] += 1\n",
    "\n",
    "#Probabilidade de palavras relevantes (não será necessário com o laplace)\n",
    "PROB_1000_I = {}\n",
    "for e in D_Irrelevante:\n",
    "    probabilidades = D_Irrelevante[e]/len(palavras_I)\n",
    "    PROB_1000_I[e] = probabilidades\n",
    "#print(PROB_1000_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade do tweet ser relevante (não será necessário com o laplace)\n",
    "Prob_tweet_R = []\n",
    "pro = 1\n",
    "for e in Lista_tweets_R:\n",
    "    for pal in PROB_1000_R:\n",
    "        if pal in e:\n",
    "            pro = pro * PROB_1000_R[pal]\n",
    "    Prob_tweet_R.append(pro)#/len(e))\n",
    "    pro = 1\n",
    "\n",
    "#print(Lista_tweets_R)\n",
    "#print(Prob_tweet_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilidade do tweet ser irrelevante (não será necessário com o laplace)\n",
    "Prob_tweet_I = []\n",
    "pro = 1\n",
    "for e in Lista_tweets_I:\n",
    "    for pal in PROB_1000_I:\n",
    "        if pal in e:\n",
    "            pro = pro * PROB_1000_I[pal]\n",
    "    Prob_tweet_I.append(pro)#/len(e))\n",
    "    pro = 1\n",
    "    \n",
    "#print(Lista_tweets_I)\n",
    "#print(len(Prob_tweet_I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dos 105 tweets marcados como relevantes, foram classificados como: \n",
      "Relevantes: 97 tweets\n",
      "Irrelevantes: 8 tweets\n"
     ]
    }
   ],
   "source": [
    "#Fazendo Laplace e testando inicialmente com tweets relevantes do treinamento\n",
    "PROB_R_LAPLACE = []\n",
    "PROB_I_LAPLACE = []\n",
    "\n",
    "for e in Lista_tweets_R:\n",
    "    \n",
    "    pro = 1\n",
    "    for pal in e:\n",
    "        if pal in D_Relevante.keys():\n",
    "            pro = pro * (D_Relevante[pal] + 1)/(len(palavras_R)+len(PALAVRAS_RI))\n",
    "        else:\n",
    "            pro = pro * (1/(len(palavras_R)+len(PALAVRAS_RI)))        \n",
    "    P1 = pro * prob_rel\n",
    "    PROB_R_LAPLACE.append(P1)\n",
    "    pro = 1\n",
    "\n",
    "    PRO = 1\n",
    "    for p in e:\n",
    "        if p in D_Irrelevante.keys():\n",
    "            PRO = PRO * (D_Irrelevante[p] + 1)/(len(palavras_I)+len(PALAVRAS_RI))\n",
    "        else:\n",
    "            PRO = PRO * (1/(len(palavras_R)+len(PALAVRAS_RI))) \n",
    "    P2 = prob_irrel * PRO\n",
    "    PROB_I_LAPLACE.append(P2)\n",
    "    PRO = 1\n",
    "    \n",
    "relevantes_positivos = []\n",
    "relevantes_negativos = []\n",
    "\n",
    "for i in range(0,len(PROB_R_LAPLACE)):\n",
    "    if PROB_R_LAPLACE[i]>PROB_I_LAPLACE[i]:\n",
    "        relevantes_positivos.append (\"OK\")\n",
    "    else:\n",
    "        relevantes_negativos.append (\"OK\")\n",
    "        \n",
    "print('Dos 105 tweets marcados como relevantes, foram classificados como: ')      \n",
    "print('Relevantes: {0} tweets'.format(len(relevantes_positivos))) \n",
    "print('Irrelevantes: {0} tweets'.format(len(relevantes_negativos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dos 195 tweets marcados como irrelevantes, foram classificados como: \n",
      "Irrelevantes: 192 tweets\n",
      "Relevantes: 3 tweets\n"
     ]
    }
   ],
   "source": [
    "#Fazendo Laplace e testando inicialmente com tweets irrelevantes do treinamento\n",
    "PROB2_R_LAPLACE = []\n",
    "PROB2_I_LAPLACE = []\n",
    "\n",
    "for e in Lista_tweets_I:\n",
    "    \n",
    "    prob = 1\n",
    "    for pal in e:\n",
    "        if pal in D_Relevante:\n",
    "            prob = prob * (D_Relevante[pal] + 1)/(len(palavras_R)+len(PALAVRAS_RI))\n",
    "        else:\n",
    "            prob = prob * (1/(len(palavras_R)+len(PALAVRAS_RI)))\n",
    "    P1 = prob_rel * prob\n",
    "    PROB2_R_LAPLACE.append(P1)\n",
    "    prob = 1    \n",
    "    \n",
    "    PRO = 1\n",
    "    for p in e:\n",
    "        if p in D_Irrelevante:\n",
    "            PRO = PRO * (D_Irrelevante[p] + 1)/(len(palavras_I)+len(PALAVRAS_RI))\n",
    "        else:\n",
    "            PRO = PRO * (1/(len(palavras_I)+len(PALAVRAS_RI)))\n",
    "    P2 = prob_irrel * PRO\n",
    "    PROB2_I_LAPLACE.append(P2)\n",
    "    PRO = 1        \n",
    "\n",
    "irrelevantes_positivos = []\n",
    "irrelevantes_negativos = []\n",
    "\n",
    "for i in range(0,len(PROB2_I_LAPLACE)):\n",
    "    if PROB2_I_LAPLACE[i]>PROB2_R_LAPLACE[i]:\n",
    "        irrelevantes_positivos.append (\"OK\")\n",
    "    else:\n",
    "        irrelevantes_negativos.append (\"OK\")\n",
    "\n",
    "print('Dos 195 tweets marcados como irrelevantes, foram classificados como: ')\n",
    "print('Irrelevantes: {0} tweets'.format(len(irrelevantes_positivos)))    \n",
    "print('Relevantes: {0} tweets'.format(len(irrelevantes_negativos)))\n",
    "#len(PROB2_I_LAPLACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando os dados agora com a base \"Teste\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importando, limpando, dividindo em relevante e irrelevante, criando os dataframes, ... como com a base \"Treinamento\"\n",
    "teste = pd.read_excel('netflix_´p2.xlsx', sheet_name=1)\n",
    "\n",
    "teste['Teste'] = teste['Teste'].str.replace(',','')\n",
    "teste['Teste'] = teste['Teste'].str.replace(':','')\n",
    "teste['Teste'] = teste['Teste'].str.replace('|','')\n",
    "teste['Teste'] = teste['Teste'].str.replace('.','')\n",
    "teste['Teste'] = teste['Teste'].str.replace('\"','')\n",
    "teste['Teste'] = teste['Teste'].str.replace('”','')\n",
    "teste['Teste'] = teste['Teste'].str.replace('“','')\n",
    "teste['Teste'] = teste['Teste'].str.replace(';','')\n",
    "teste['Teste'] = teste['Teste'].str.replace('!',' !')\n",
    "teste['Teste'] = teste['Teste'].str.replace('?',' ?')\n",
    "teste['Teste'] = teste['Teste'].str.replace('(','')\n",
    "teste['Teste'] = teste['Teste'].str.replace('+','')\n",
    "teste['Teste'] = teste['Teste'].str.replace(')','')\n",
    "teste['Teste'] = teste['Teste'].str.replace('\\n','')\n",
    "teste['Teste'] = teste['Teste'].str.replace('/','')\n",
    "teste['Teste'] = teste['Teste'].str.strip()\n",
    "teste['Teste'] = teste['Teste'].str.lower()\n",
    "\n",
    "teste_relevantes = teste[teste['R ou I']=='Relevante']\n",
    "teste_irrelevantes = teste[teste['R ou I']=='Irrelevante']\n",
    "\n",
    "teste_lista_palavras_rel = teste_relevantes['Teste'].str.split()\n",
    "teste_lista_palavras_irrel = teste_irrelevantes['Teste'].str.split()\n",
    "\n",
    "teste_R = pd.DataFrame(np.array(teste_lista_palavras_rel), columns=['Relevantes'])\n",
    "teste_I = pd.DataFrame(np.array(teste_lista_palavras_irrel), columns=['Irrelevantes'])\n",
    "\n",
    "for linha in teste_R['Relevantes']:\n",
    "    for p in linha:\n",
    "        if '@' in p:\n",
    "            linha.remove(p)\n",
    "        if 'https'in p:\n",
    "            linha.remove(p)\n",
    "        if ' ' in p:\n",
    "            linha.remove(p)\n",
    "            \n",
    "for li in teste_I['Irrelevantes']:\n",
    "    for palo in li:\n",
    "        if '@' in palo:\n",
    "            li.remove(palo)\n",
    "        if ' ' in palo:\n",
    "            li.remove(palo)\n",
    "            \n",
    "Tweets_teste_R = []\n",
    "for listas in teste_R[\"Relevantes\"]:\n",
    "    Tweets_teste_R.append(listas)\n",
    "Tweets_teste_I = []\n",
    "for listas in teste_I[\"Irrelevantes\"]:\n",
    "    Tweets_teste_I.append(listas)\n",
    "\n",
    "#print(len(Tweets_teste_I))\n",
    "#print(len(Tweets_teste_R))\n",
    "len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dos tweets já marcados como relevantes, a probabilidade destes serem relevantes (1ªprob) e irrelevantes (2ªprob) são: \n",
      "62.5 % e\n",
      "37.5 %\n"
     ]
    }
   ],
   "source": [
    "#Usando Laplace para calcular, a partir do nosso banco de dados, a probabilidade dos tweets relevantes \"Testes\" serem relevantes\n",
    "R_LAPLACE = []\n",
    "I_LAPLACE = []\n",
    "\n",
    "for e in Tweets_teste_R:\n",
    "    \n",
    "    pro = 1\n",
    "    for pal in e:\n",
    "        if pal in D_Relevante.keys():\n",
    "            pro = pro * (D_Relevante[pal] + 1)/(len(palavras_R)+len(PALAVRAS_RI))\n",
    "        else:\n",
    "            pro = pro * (1/(len(palavras_R)+len(PALAVRAS_RI))) \n",
    "        \n",
    "    \n",
    "    P1 = pro * prob_rel\n",
    "    R_LAPLACE.append(P1)\n",
    "    pro = 1\n",
    "\n",
    "    PRO = 1\n",
    "    for p in e:\n",
    "        if p in D_Irrelevante.keys():\n",
    "            PRO = PRO * (D_Irrelevante[p] + 1)/(len(palavras_I)+len(PALAVRAS_RI))\n",
    "        else:\n",
    "            PRO = PRO * (1/(len(palavras_R)+len(PALAVRAS_RI))) \n",
    "    P2 = prob_irrel * PRO\n",
    "    I_LAPLACE.append(P2)\n",
    "    PRO = 1\n",
    "\n",
    "    \n",
    "Positivos_verdadeiros = []\n",
    "Negativos_falsos = []\n",
    "\n",
    "for i in range(0,len(R_LAPLACE)):\n",
    "    if R_LAPLACE[i]>I_LAPLACE[i]:\n",
    "        Positivos_verdadeiros.append (\"OK\")\n",
    "    else:\n",
    "        Negativos_falsos.append (\"OK\")\n",
    "        \n",
    "pos_ved = len(Positivos_verdadeiros)/len(teste)\n",
    "neg_fal = len(Negativos_falsos)/len(teste)\n",
    "\n",
    "print('Dos tweets já marcados como relevantes, a probabilidade destes serem relevantes (1ªprob) e irrelevantes (2ªprob) são: ')\n",
    "print('{0} % e'.format((len(Positivos_verdadeiros)/len(R_LAPLACE))*100)) #marcados como rele sendo rele #positivos verdadeiros\n",
    "print('{0} %'.format((len(Negativos_falsos)/len(R_LAPLACE))*100)) #marcados como irre sendo rele #negativos falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dos tweets já marcados como irrelevantes, a probabilidade destes serem irrelevantes (1ªprob) e relevantes (2ªprob) são: \n",
      "93.75 % e\n",
      "6.25 %\n"
     ]
    }
   ],
   "source": [
    "#Como no anterior, com o nosso banco de dados, calculamos a probabilidade dos tweets \"Testes\" irrelevantes serem irrelevantes\n",
    "R2_LAPLACE = []\n",
    "I2_LAPLACE = []\n",
    "\n",
    "for e in Tweets_teste_I:\n",
    "    \n",
    "    pro = 1\n",
    "    for pal in e:\n",
    "        if pal in D_Relevante.keys():\n",
    "            pro = pro * (D_Relevante[pal] + 1)/(len(palavras_R)+len(PALAVRAS_RI))\n",
    "        else:\n",
    "            pro = pro * (1/(len(palavras_R)+len(PALAVRAS_RI))) \n",
    "          \n",
    "    P1 = pro * prob_rel\n",
    "    R2_LAPLACE.append(P1)\n",
    "    pro = 1\n",
    "\n",
    "    PRO = 1\n",
    "    for p in e:\n",
    "        if p in D_Irrelevante.keys():\n",
    "            PRO = PRO * (D_Irrelevante[p] + 1)/(len(palavras_I)+len(PALAVRAS_RI))\n",
    "        else:\n",
    "            PRO = PRO * (1/(len(palavras_R)+len(PALAVRAS_RI))) \n",
    "    P2 = prob_irrel * PRO\n",
    "    I2_LAPLACE.append(P2)\n",
    "    PRO = 1\n",
    "\n",
    "    \n",
    "Negativos_verdadeiros = []\n",
    "Positivos_falsos = []\n",
    "\n",
    "for i in range(0,len(I2_LAPLACE)):\n",
    "    if I2_LAPLACE[i]>R2_LAPLACE[i]:\n",
    "        Negativos_verdadeiros.append (\"OK\")\n",
    "    else:\n",
    "        Positivos_falsos.append (\"OK\")\n",
    "    \n",
    "neg_ved = len(Negativos_verdadeiros)/len(teste)\n",
    "pos_fal = len(Positivos_falsos)/len(teste)\n",
    "\n",
    "print('Dos tweets já marcados como irrelevantes, a probabilidade destes serem irrelevantes (1ªprob) e relevantes (2ªprob) são: ')\n",
    "print('{0} % e'.format((len(Negativos_verdadeiros)/len(I2_LAPLACE))*100)) #marcado como irre sendo irre #negativos verdadeiros\n",
    "print('{0} %'.format((len(Positivos_falsos)/len(I2_LAPLACE))*100)) #marcado como rele sendo irre #positivos falsos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando também com um tweet aleatório qualquer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevante\n"
     ]
    }
   ],
   "source": [
    "ahoi = ['netflix', 'americano', 'é', 'melhor']\n",
    "pb = []\n",
    "pro = 1\n",
    "for pala in ahoi:\n",
    "    \n",
    "    if pala in D_Relevante.keys():\n",
    "        pro = pro * (D_Relevante[pala] + 1)/(len(palavras_R)+len(PALAVRAS_RI))\n",
    "    else:\n",
    "        pro = pro * (1/(len(palavras_R)+len(PALAVRAS_RI)))\n",
    "pb.append(pro)\n",
    "\n",
    "PRO = 1\n",
    "for plvra in ahoi:\n",
    "    \n",
    "    if plvra in D_Irrelevante.keys():\n",
    "        PRO = PRO * (D_Irrelevante[plvra] + 1)/(len(palavras_I)+len(PALAVRAS_RI))\n",
    "    else:\n",
    "        PRO = PRO * (1/(len(palavras_R)+len(PALAVRAS_RI)))\n",
    "pb.append(PRO)\n",
    "\n",
    "if pb[0] > pb[1]:\n",
    "    print('Relevante')\n",
    "else:\n",
    "    print('Nha') #Irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verdadeiro</th>\n",
       "      <th>Falso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Verdadeiro  Falso\n",
       "Relevante         0.225  0.135\n",
       "Irrelevante       0.600  0.040"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fato = ['Relevante', 'Irrelevante']\n",
    "Classificação = ['Verdadeiro', 'Falso']\n",
    "valores = [[pos_ved,neg_fal],[neg_ved,pos_fal]]\n",
    "\n",
    "crosstab = pd.DataFrame(np.array(valores), index=Fato, columns = Classificação)\n",
    "\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela acima, apresenta em sua primeira linha, as probabilidades dos tweets classificados como relevantes no excel e que, foram marcados como tais pelo sistema (Relevantes Verdadeiro) ou marcados como irrelevantes pelo sistema (Relevantes Falso). Na segunda linha, se apresenta o mesmo princípio, os tweets classificados como irrelevantes no excel e que foram, marcados como irrelevantes pelo Naive-Bayes (Irrelevantes Verdadeiros) ou marcados como relevantes (Irrelevantes Falsos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos Verdadeiros 22.5 %\n",
      "Negativos Falsos 13.5 %\n",
      "Negativos Verdadeiros 60.0 %\n",
      "Positivos Falsos 4.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verdadeiro</th>\n",
       "      <th>Falso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positivo</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negativo</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Verdadeiro  Falso\n",
       "Positivo       0.225  0.040\n",
       "Negativo       0.600  0.135"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dado = ['Positivo', 'Negativo']\n",
    "val = [[pos_ved, pos_fal], [neg_ved,neg_fal]]\n",
    "\n",
    "print('Positivos Verdadeiros {0} %'.format(pos_ved*100)) #marcados como rele sendo rele #positivos verdadeiros\n",
    "print('Negativos Falsos {0} %'.format(neg_fal*100))  #marcados como irre sendo rele #negativos falsos\n",
    "print('Negativos Verdadeiros {0} %'.format(neg_ved*100)) #marcado como irre sendo irre #negativos verdadeiros\n",
    "print('Positivos Falsos {0} %'.format(pos_fal*100)) #marcado como rele sendo irre #positivos falsos\n",
    "\n",
    "pd.DataFrame(np.array(val), index=dado, columns = Classificação)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo...\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão:\n",
    "\n",
    "O classificador Naive-Bayes poderia ser utilizado para inúmeras funções, tal como determinar se a pessoa possui ou não uma certa doença, usando como base de dados, sintomas, ocorrências e a resposta do médico, classificando os examinados em apresentar sintomas da doença, mas não estar doente ou não apresentar sintomas e não ter a doença, etc. Outro exemplo seria utilizar esse sistema para calcular as probabilidades de classificar uma fruta, dada algumas características. O Naive-Bayes também pode ser utilizado no cenário político, em que pode-se analisar a opinião pública e projetar as probabilidades de cada candidato vencer a eleição. Contudo, nesse projeto utilizamos o classificador para identificar e analisar mensagens de opinião sobre um produto, no nosso caso o Netflix.\n",
    "\n",
    "Após terminar de desenvolver o nosso classificador e testá-lo em vários tweets, foi possível chegar à conclusão de que o classificador criado a partir do Naive-Bayes não é perfeito e apresenta erros. Dentre os 72 classificados como relevantes, 45 foram marcados como realmente relevantes pelo sistema e 27 como não relevantes (61.64% de acerto e 38.36% de erro, olhando apenas os classificados como relevantes por nós). Já dos 128 classificados como irrelevante, 93.70% deles foram marcados corretamente, enquanto que os 6.30% restantes foram marcados como sendo relevantes. Ou seja, para os irrelevantes, o número de Positivos Falsos obtido pelo classificador foi bem pequeno, trazendo certa confiabilidade para ele. Apesar que, como há uma taxa significativa de Negativos Falsos, pode-se dizer por outro lado que esse classificador também não é muito eficiente, já que este apresenta um índice razoável de erros.\n",
    "\n",
    "O número de Negativos Falsos deve-se principalmente ao fato de haver, nos tweets analisados, mais tweets irrelevantes do que relevantes. Assim, os artigos, preposições e verbos de ligação por exemplo, que aparecem mais e não trazem nenhum conteúdo relevante para análise, aumentam as probabilidades dos tweets de serem irrelevantes. Ademais, dentre os tweets há mensagens com dupla negação e sarcasmo. Como o Naive-Bayes trata cada palavra do tweet individualmente, ele não junta o sentido de duas palavras; logo, quando há dupla negação, ou seja, duas palavras negativas se anulam, ele pode classificar o tweet incoerentemente ao que seria desejado, o que também contribui para o aumento de erros. O mesmo acontece para o sarcasmo, já que algumas palavras possuem duplo sentido, podendo significar duas coisas diferentes. Dessa forma, quando o classificador passar por uma palavra, ele não irá considerar o contexto dela, e sim o fato dela ocorrer. Assim, um tweet considerado relevante que possui uma palavra ambígua ou utiliza sarcasmo, pode ser marcado como irrelevante, já que ele ve a palavra com outro sentido. \n",
    "\n",
    "Dessa forma, propomos um plano de expansão possibilite ampliar a análise dos dados, se iniciando por uma melhor limpeza e poda dos dados. Além disso, outra forma que poderia melhorar drasticamente o classificador seria se conseguíssimos juntar palavras, o que também ampliaria a análise, já que algumas palavras ao ficarem sozinhas, perdem parte de seu sentido original. Para melhorar ainda mais, não devemos alimentar a base \"Treinamento\" automaticamente usando o nosso próprio classificador, pois assim estaríamos transferindo esse erro, fazendo com que ele aumente cada vez mais (como uma \"bola de neve\"). Isso pode ser explicados pelo fato de que como já há um erro, os valores calculados equivocadamente transfeririam essa falha para frente. O correto seria explorar outras formas, como por exemplo aumentar a base de dados (tweets classificados manualmente por nós que estarão 100% de acordo com o que a empresa considera relevante ou não), possibilitando mais informações, que tornarão o cálculo mais preciso. \n",
    "\n",
    "Por fim, defendemos o fato de que esse projeto deve continuar a ser financiado, pois como esse produto é utilizado por milhões de pessoas, quanto mais se souber sobre a opinião dos usuários, melhor serão as melhorias realizadas, trazendo um ambiente cada vez mais satisfatório e de acordo com o interesse do cliente, o que acarretará em mais pessoas felizes, querendo assinar com a empresa e assim por diante, ou seja, um ciclo virtuoso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referêrencias:**\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
